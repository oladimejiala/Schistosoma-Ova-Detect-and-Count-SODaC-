{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oladimejiala/Schistosoma-Ova-Detect-and-Count-SODaC-Model/blob/first/Training_Parasite_Image_datasets_Using_Convluted_Neural_Networks_(CNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "HmUMcwhwL1OP"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "# from keras.optimizers import RMSprop\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import imutils\n",
        "import cv2\n",
        "import os\n",
        "import openai\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evPDouwQGC5F",
        "outputId": "bdb8ad41-c819-4636-a104-cf22ccae23ac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "S5Ae4nnBMF3B",
        "outputId": "8b0d97fc-fc68-4935-ca70-39ef96cd5b00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AIzaSyBpPI6IMlltRi7EIh6rWGZ_ajZIskPOU2s'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "SuyXjgAJPv9x"
      },
      "outputs": [],
      "source": [
        "# testing ai response from openai model\n",
        "# res = userdata.chat.completions.create( # Changed openai.ChatCompletion.create to openai.chat.completions.create\n",
        "#     model=\"gpt-3.5-turbo\",\n",
        "#     messages=[{\"role\": \"user\", \"content\": \"write an alorithm that learns the structure of Schiistosomes ova and gives valid description of observed ove \"}]\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "e8aiDuDDL1OU",
        "outputId": "6c672466-9c82-4568-c42a-9e0b0dfd562c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical # this is to_categorical method of one-hot encoding of label in classification models\n",
        "\n",
        "# List of string labels\n",
        "labels = ['Schistosoma haematobium', 'Schistosoma intercalatum', 'Schistosoma japonicum', 'Schistosoma mansoni', 'Schistosoma mekongi']\n",
        "\n",
        "# Dictionary mapping string labels to integer labels\n",
        "label_dict = {'Schistosoma haematobium': 0, 'Schistosoma intercalatum': 1, 'Schistosoma japonicum': 2, 'Schistosoma mansoni': 3, 'Schistosoma mekongi': 4}\n",
        "\n",
        "# Convert string labels to integer labels\n",
        "int_labels = [label_dict[label] for label in labels]\n",
        "\n",
        "# One-hot encode integer labels\n",
        "one_hot_labels = to_categorical(int_labels, num_classes=5)\n",
        "\n",
        "print(one_hot_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a7yxa6HL1OW"
      },
      "source": [
        "The preprocessing step is an important part of the image classification pipeline as it can help to enhance features that distinguish the different species of Schistosoma. Here's an example of how to preprocess the images using OpenCV:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "p5vFMEErL1OY"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_image(image_path, image_size):\n",
        "    # Load image and resize to desired size\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, image_size)\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply histogram equalization to enhance contrast\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    equalized = clahe.apply(gray)\n",
        "\n",
        "    # Apply thresholding to binarize the image\n",
        "    _, thresholded = cv2.threshold(equalized, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "\n",
        "    # Apply median filtering to remove noise\n",
        "    denoised = cv2.medianBlur(thresholded, 3)\n",
        "\n",
        "    # Apply dilation and erosion to enhance features\n",
        "    kernel = np.ones((3,3), np.uint8)\n",
        "    dilated = cv2.dilate(denoised, kernel, iterations=1)\n",
        "    eroded = cv2.erode(dilated, kernel, iterations=1)\n",
        "\n",
        "    # Convert back to color and normalize pixel values to range [0, 1]\n",
        "    processed_image = cv2.cvtColor(eroded, cv2.COLOR_GRAY2RGB)\n",
        "    processed_image = processed_image.astype(\"float32\") / 255.0\n",
        "\n",
        "    return processed_image\n",
        "\n",
        "# calling this function:\n",
        "# preprocess_image()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFXcMfneL1OZ"
      },
      "source": [
        "The cell below, ImageDataGenerator from Keras was used to perform data augmentation, normalization, and resizing. We also define the input shape of the model, the batch size, and the paths to the train, validation, and test data directories. Finally, we use the data generators to load the images from the directories. Note that flow_from_directory method is used to load the images and their labels from the directories in batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "mDKJBxuAL1Oa",
        "outputId": "29b4e8a0-2131-4a7b-a916-7ddc0166624f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Mike_Dev\\\\Desktop\\\\Schisto images\\\\train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-1fe84dfec5ed>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Use the data generators to load the images from the directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m train_generator = train_datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ):\n\u001b[0;32m-> 1138\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1139\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Mike_Dev\\\\Desktop\\\\Schisto images\\\\train'"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define the data generator for training set\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # normalize the pixel values to range [0,1]\n",
        "    rotation_range=20,  # randomly rotate the images by up to 20 degrees\n",
        "    width_shift_range=0.1,  # randomly shift the images horizontally by up to 10% of the width\n",
        "    height_shift_range=0.1,  # randomly shift the images vertically by up to 10% of the height\n",
        "    shear_range=0.1,  # randomly shear the images by up to 10%\n",
        "    zoom_range=0.1,  # randomly zoom the images by up to 10%\n",
        "    horizontal_flip=True,  # randomly flip the images horizontally\n",
        "    fill_mode='nearest'  # fill in any missing pixels with the nearest pixel value\n",
        ")\n",
        "\n",
        "# Define the data generator for validation and test sets\n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale=1./255  # normalize the pixel values to range [0,1]\n",
        ")\n",
        "\n",
        "# Define the input shape for the model\n",
        "input_shape = (200, 200, 3)\n",
        "\n",
        "# Define the batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Define the paths to the train, validation, and test data directories\n",
        "train_dir = r'C:\\Users\\Mike_Dev\\Desktop\\Schisto images\\train'\n",
        "# val_dir = r'C:\\Users\\Mike_Dev\\Desktop\\Schisto images\\validation'\n",
        "# test_dir = r'C:\\Users\\Mike_Dev\\Desktop\\Schisto images\\test'\n",
        "\n",
        "# Use the data generators to load the images from the directories\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_generator = val_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JieerjhLL1Ob"
      },
      "source": [
        "The code above defines data generators for the training and validation data, sets the directory paths and image size, and uses data augmentation and normalization to preprocess the images. The fit method is then used to train the model for 10 epochs using the training data and validate it using the validation data. The training history is stored in the history object, which can be used for further analysis and visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyhcyBAHL1Ob",
        "outputId": "1b14f762-c6dc-47b3-f8fc-31fb2a851791"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Mike_Dev\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 198, 198, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 99, 99, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 97, 97, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 48, 48, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 46, 46, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 23, 23, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 67712)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               8667264   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 8,761,157\n",
            "Trainable params: 8,761,157\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnKaNUjxL1Oc",
        "outputId": "ec266d72-f993-4950-8332-e9163da55749"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 64 images belonging to 5 classes.\n",
            "Found 64 images belonging to 5 classes.\n",
            "Epoch 1/40\n",
            "4/4 [==============================] - 19s 5s/step - loss: 2.1304 - acc: 0.2188 - val_loss: 1.4571 - val_acc: 0.4375\n",
            "Epoch 2/40\n",
            "4/4 [==============================] - 8s 2s/step - loss: 1.4466 - acc: 0.3594 - val_loss: 1.2511 - val_acc: 0.4375\n",
            "Epoch 3/40\n",
            "4/4 [==============================] - 7s 2s/step - loss: 1.2626 - acc: 0.5156 - val_loss: 1.2732 - val_acc: 0.3906\n",
            "Epoch 4/40\n",
            "4/4 [==============================] - 8s 2s/step - loss: 1.3484 - acc: 0.3281 - val_loss: 1.1783 - val_acc: 0.5000\n",
            "Epoch 5/40\n",
            "4/4 [==============================] - 8s 2s/step - loss: 1.2389 - acc: 0.3750 - val_loss: 1.1794 - val_acc: 0.4062\n",
            "Epoch 6/40\n",
            "4/4 [==============================] - 8s 2s/step - loss: 1.2302 - acc: 0.4062 - val_loss: 1.0864 - val_acc: 0.5000\n",
            "Epoch 7/40\n",
            "4/4 [==============================] - 8s 2s/step - loss: 1.1089 - acc: 0.5781 - val_loss: 1.0161 - val_acc: 0.5781\n",
            "Epoch 8/40\n",
            "4/4 [==============================] - 8s 2s/step - loss: 1.0632 - acc: 0.5625 - val_loss: 0.9999 - val_acc: 0.5312\n",
            "Epoch 9/40\n",
            "4/4 [==============================] - 8s 2s/step - loss: 1.1685 - acc: 0.5000 - val_loss: 0.9509 - val_acc: 0.6875\n",
            "Epoch 10/40\n",
            "4/4 [==============================] - 8s 2s/step - loss: 1.0166 - acc: 0.5156 - val_loss: 1.0058 - val_acc: 0.5469\n",
            "Epoch 11/40\n",
            "4/4 [==============================] - 7s 2s/step - loss: 1.0564 - acc: 0.5000 - val_loss: 0.9634 - val_acc: 0.6094\n",
            "Epoch 12/40\n",
            "4/4 [==============================] - 7s 2s/step - loss: 1.1082 - acc: 0.6562 - val_loss: 0.9704 - val_acc: 0.7031\n",
            "Epoch 13/40\n",
            "4/4 [==============================] - 8s 2s/step - loss: 1.0966 - acc: 0.5312 - val_loss: 0.8582 - val_acc: 0.7188\n",
            "Epoch 14/40\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.9861 - acc: 0.5938 - val_loss: 0.7773 - val_acc: 0.7188\n",
            "Epoch 15/40\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.8800 - acc: 0.6562 - val_loss: 0.7055 - val_acc: 0.6719\n",
            "Epoch 16/40\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.8868 - acc: 0.6719 - val_loss: 0.7065 - val_acc: 0.7500\n",
            "Epoch 17/40\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.7824 - acc: 0.6562 - val_loss: 0.6905 - val_acc: 0.6875\n",
            "Epoch 18/40\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.7955 - acc: 0.6719 - val_loss: 0.5583 - val_acc: 0.7656\n",
            "Epoch 19/40\n",
            "4/4 [==============================] - 8s 2s/step - loss: 0.6686 - acc: 0.7188 - val_loss: 0.6458 - val_acc: 0.6875\n",
            "Epoch 20/40\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.6154 - acc: 0.6875 - val_loss: 0.4842 - val_acc: 0.8438\n",
            "Epoch 21/40\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.6020 - acc: 0.7500 - val_loss: 0.5267 - val_acc: 0.7500\n",
            "Epoch 22/40\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.7335 - acc: 0.7188 - val_loss: 0.5753 - val_acc: 0.7500\n",
            "Epoch 23/40\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.9233 - acc: 0.6562 - val_loss: 0.4940 - val_acc: 0.8750\n",
            "Epoch 24/40\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.7510 - acc: 0.6719 - val_loss: 0.6971 - val_acc: 0.6562\n",
            "Epoch 25/40\n",
            "4/4 [==============================] - 6s 1s/step - loss: 0.6167 - acc: 0.7344 - val_loss: 0.5333 - val_acc: 0.7500\n",
            "Epoch 26/40\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.5747 - acc: 0.7031 - val_loss: 0.3841 - val_acc: 0.8594\n",
            "Epoch 27/40\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.5374 - acc: 0.8125 - val_loss: 0.3743 - val_acc: 0.8438\n",
            "Epoch 28/40\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.4520 - acc: 0.7812 - val_loss: 0.3464 - val_acc: 0.8281\n",
            "Epoch 29/40\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.6309 - acc: 0.7656 - val_loss: 0.4826 - val_acc: 0.7812\n",
            "Epoch 30/40\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.5348 - acc: 0.7812 - val_loss: 0.3929 - val_acc: 0.8594\n",
            "Epoch 31/40\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.4978 - acc: 0.7500 - val_loss: 0.3886 - val_acc: 0.8281\n",
            "Epoch 32/40\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.4093 - acc: 0.8594 - val_loss: 0.2662 - val_acc: 0.8906\n",
            "Epoch 33/40\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.4140 - acc: 0.8594 - val_loss: 0.2934 - val_acc: 0.8750\n",
            "Epoch 34/40\n",
            "4/4 [==============================] - 6s 1s/step - loss: 0.4354 - acc: 0.8125 - val_loss: 0.2678 - val_acc: 0.9062\n",
            "Epoch 35/40\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.3966 - acc: 0.9062 - val_loss: 0.3983 - val_acc: 0.8438\n",
            "Epoch 36/40\n",
            "4/4 [==============================] - 6s 1s/step - loss: 0.4500 - acc: 0.7500 - val_loss: 0.3223 - val_acc: 0.8750\n",
            "Epoch 37/40\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.2920 - acc: 0.8906 - val_loss: 0.1800 - val_acc: 0.9375\n",
            "Epoch 38/40\n",
            "4/4 [==============================] - 6s 1s/step - loss: 0.2637 - acc: 0.9219 - val_loss: 0.2720 - val_acc: 0.8438\n",
            "Epoch 39/40\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.2501 - acc: 0.8750 - val_loss: 0.1702 - val_acc: 0.9375\n",
            "Epoch 40/40\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.3087 - acc: 0.8906 - val_loss: 0.2497 - val_acc: 0.8750\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define data generators for training and validation data\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Set the directory paths for the training and validation data\n",
        "# train_dir = 'path/to/train/data'\n",
        "# val_dir = 'path/to/validation/data'\n",
        "\n",
        "# Set the image size and batch size for training and validation data\n",
        "img_size = (200, 200)\n",
        "batch_size = 16\n",
        "\n",
        "# Generate the training and validation data batches\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        val_dir,\n",
        "        target_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples // batch_size,\n",
        "        epochs=40,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=validation_generator.samples // batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGi6IoPhL1Od",
        "outputId": "3fed6319-d92c-46d0-92c5-8dbaee542240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 29s 7s/step - loss: 0.3221 - acc: 0.9531 - val_loss: 0.0800 - val_acc: 0.9688\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 29s 7s/step - loss: 0.1486 - acc: 0.9375 - val_loss: 0.0939 - val_acc: 0.9688\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 28s 7s/step - loss: 0.0583 - acc: 0.9844 - val_loss: 0.0687 - val_acc: 0.9688\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 28s 7s/step - loss: 0.0682 - acc: 0.9844 - val_loss: 0.0518 - val_acc: 0.9844\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 28s 7s/step - loss: 0.0652 - acc: 0.9844 - val_loss: 0.0698 - val_acc: 0.9688\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 30s 8s/step - loss: 0.0612 - acc: 0.9688 - val_loss: 0.0793 - val_acc: 0.9688\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 27s 7s/step - loss: 0.0732 - acc: 0.9531 - val_loss: 0.0346 - val_acc: 0.9844\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 28s 7s/step - loss: 0.0330 - acc: 1.0000 - val_loss: 0.0307 - val_acc: 0.9844\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 29s 7s/step - loss: 0.0397 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 1.0000\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 28s 7s/step - loss: 0.0222 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 0.9844\n",
            "2/2 [==============================] - 5s 3s/step - loss: 0.0172 - acc: 0.9844\n",
            "Test accuracy: 0.9844\n",
            "Test Loss: 0.0172\n"
          ]
        }
      ],
      "source": [
        "# Train the model on the preprocessed data\n",
        "history = model.fit(train_generator, epochs=10, validation_data=val_generator)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "\n",
        "model.save(r\"C:\\\\Users\\Mike_Dev\\Desktop\\Schisto images\\schistosoma_ova_classifier.h5\")\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb5pqEU5L1Oe"
      },
      "source": [
        "From above:\n",
        "first run: A test accuracy of 0.953125 and test loss of 0.1164017990231514 indicate that the model is performing very well on the test set. It means that the model correctly classified 95.31% of the test data and has a low error rate of 0.116. These are good performance metrics, indicating that the model is able to generalize well to unseen data.\n",
        "\n",
        "Third run: using f-strings gives\n",
        "Test accuracy: 0.9844\n",
        "Test Loss: 0.0454"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmqHb-dgL1Oe"
      },
      "source": [
        "In the model evaluation cell below, only one image data was used to evaluate the model which gives 0.2000 i.e 20% accuracy of the while the one above gave 98.44% based on numerous test data used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyWUZNohL1Of"
      },
      "outputs": [],
      "source": [
        "# # Evaluate the model on the test set\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "# from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "# label_encoder = LabelEncoder()\n",
        "# # processed_image = preprocess_image(image_path=r\"C:\\Users\\Mike_Dev\\Desktop\\Schisto images\\train\", image_size=(200, 200))\n",
        "# test_data = preprocess_image(r\"C:\\Users\\Mike_Dev\\Desktop\\Schistosoma mansoni.jpg\", (200, 200))[np.newaxis, ...]\n",
        "# test_data = np.repeat(test_data, 5, axis=0)\n",
        "# test_labels = ['Schistosoma haematobium', 'Schistosoma intercalatum', 'Schistosoma japonicum', 'Schistosoma mansoni', 'Schistosoma mekongi'] # assign the appropriate label to the test_data\n",
        "\n",
        "# # encode the labels as one-hot vectors\n",
        "# test_labels_encoded = to_categorical(label_encoder.fit_transform(test_labels))\n",
        "\n",
        "# # evaluate the model on the test set\n",
        "# loss, accuracy = model.evaluate(test_data, test_labels_encoded)\n",
        "# print(f\"Test Loss: {loss:.4f}\")\n",
        "# print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "# # loss, accuracy = model.evaluate(np.array([test_data]), np.array([test_labels]))\n",
        "# # print(f\"Test Loss: {loss:.4f}\")\n",
        "# # print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# \"\"\"\n",
        "# You can also use the predict() method of the model to get the predicted\n",
        "# labels for the test set, and compare them with the true labels to get a\n",
        "# more detailed performance analysis.\n",
        "# \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdvpU1DVL1Og"
      },
      "outputs": [],
      "source": [
        "# # alternatively using the pretrained VGG model.\n",
        "# from tensorflow.keras.applications.vgg16 import VGG16\n",
        "# model = VGG16()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYvH8nkYL1Og"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.preprocessing import image\n",
        "# from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "# img = image.load_img('path/to/image.jpg', target_size=(224, 224))\n",
        "# x = image.img_to_array(img)\n",
        "# x = preprocess_input(x)\n",
        "\n",
        "# import numpy as np\n",
        "\n",
        "# preds = model.predict(np.array([x]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_yDi4RtL1Og"
      },
      "source": [
        "Integrating the Convolutional Neural Network Model into Schistosoma ova detection Function. - This is the first one today, but seem not working."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x90545ctL1Oh"
      },
      "outputs": [],
      "source": [
        "# import cv2\n",
        "# import tensorflow as tf\n",
        "\n",
        "# class SchistosomaOvaCounter(tf.keras.layers.Layer):\n",
        "#     def __init__(self):\n",
        "#         super(SchistosomaOvaCounter, self).__init__()\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         image_path = inputs.numpy()[0].decode()\n",
        "\n",
        "#         # Load the image\n",
        "#         image = cv2.imread(image_path)\n",
        "\n",
        "#         # Predict the species of Schistosoma based on the filename\n",
        "#         if \"haematobium\" in image_path.lower():\n",
        "#             species = \"haematobium\"\n",
        "#             ovum_mask = predict_haematobium(image)\n",
        "#         elif \"mansoni\" in image_path.lower():\n",
        "#             species = \"mansoni\"\n",
        "#             ovum_mask = predict_mansoni(image)\n",
        "#         elif \"intercalatum\" in image_path.lower():\n",
        "#             species = \"intercalatum\"\n",
        "#             ovum_mask = predict_intercalatum(image)\n",
        "#         elif \"japonicum\" in image_path.lower():\n",
        "#             species = \"japonicum\"\n",
        "#             ovum_mask = predict_japonicum(image)\n",
        "#         elif \"mekongi\" in image_path.lower():\n",
        "#             species = \"mekongi\"\n",
        "#             ovum_mask = predict_mekongi(image)\n",
        "#         else:\n",
        "#             lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "#             l, a, b = cv2.split(lab_image)\n",
        "#             clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
        "#             l = clahe.apply(l)\n",
        "#             image = cv2.merge([l,a,b])\n",
        "#             hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "#             green_mask = cv2.inRange(hsv_image, (36, 25, 25), (86, 255,255))\n",
        "#             ovum_mask = cv2.bitwise_not(green_mask)\n",
        "\n",
        "#         # Use the pretrained model to predict the presence of ova\n",
        "#         resized_image = cv2.resize(image, (200, 200))\n",
        "#         resized_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
        "#         resized_image = resized_image.astype('float32') / 255.0\n",
        "#         prediction = model.predict(tf.expand_dims(resized_image, axis=0), steps=1)[0]\n",
        "#         has_ova = prediction[1] > prediction[0]\n",
        "\n",
        "#         # Count the number of ovum of the predicted species in the image\n",
        "#         if has_ova:\n",
        "#             lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "#             ovum_mask = cv2.medianBlur(ovum_mask, 5)\n",
        "#             ovum_mask = cv2.morphologyEx(ovum_mask, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9)))\n",
        "#             ovum_mask = cv2.morphologyEx(ovum_mask, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15)))\n",
        "#             contours, _ = cv2.findContours(ovum_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "#             num_ovum = len(contours)\n",
        "#         else:\n",
        "#             num_ovum = 0\n",
        "\n",
        "#         return tf.constant([num_ovum], dtype=tf.float32), tf.constant([species], dtype=tf.string)\n",
        "\n",
        "# # Load the pretrained model\n",
        "# # model = tf.keras.models.load_model('schistosoma_ova_classifier.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMKm0gzfL1Oi"
      },
      "outputs": [],
      "source": [
        "# Define a Keras model with SchistosomaOvaCounter as its output layer\n",
        "# input_tensor = tf.keras.Input(shape=(1,), dtype=tf.string)\n",
        "# output_tensor = SchistosomaOvaCounter()(input_tensor)\n",
        "# model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
        "\n",
        "# # Count the number of ovum in the image and print the result\n",
        "# image_path = 'test_image.jpg'\n",
        "# num_ovum, species = model.predict(np.array([image_path]))\n",
        "# print(f\"There are {num_ovum} Schistosoma {species} ova in the image.\")\n",
        "\n",
        "# # Create the input prompt for the user\n",
        "# print(\"Enter the path to the image file:\")\n",
        "# image_path = input()\n",
        "\n",
        "# # Count the number of ovum in the image and print the result\n",
        "# num_ovum, species = SchistosomaOvaCounter(image_path)\n",
        "# print(f\"There are {num_ovum} Schistosoma {species} ova in the image.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFODICQxL1Oj"
      },
      "outputs": [],
      "source": [
        "# image_path = \"/path/to/your/image.jpg\"\n",
        "# image_tensor = tf.constant([image_path], dtype=tf.string)\n",
        "# schisto_ova_counter = SchistosomaOvaCounter()\n",
        "# num_ovum, species = schisto_ova_counter(image_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nsci_KC4L1Oj"
      },
      "source": [
        "Integrating the Convolutional Neural Network Model into Schistosoma ova detection Function. - This is the second one today: 1/04/2023."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBSsPh_ZL1Oj"
      },
      "outputs": [],
      "source": [
        "# # Import necessary libraries\n",
        "# import tensorflow as tf\n",
        "# import numpy as np\n",
        "# import cv2\n",
        "\n",
        "# # Define SchistosomaOvaCounter class\n",
        "# class SchistosomaOvaCounter(tf.keras.Model):\n",
        "\n",
        "#     def __init__(self):\n",
        "#         super(SchistosomaOvaCounter, self).__init__()\n",
        "#         self.model = tf.keras.models.load_model('schistosoma_model.h5')\n",
        "#         self.species_mapping = {0: 'S. haematobium', 1: 'S. mansoni'}\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         image_path = inputs.numpy()[0].decode()\n",
        "\n",
        "#         # Load the image\n",
        "#         img = cv2.imread(image_path)\n",
        "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "#         img = cv2.resize(img, (224, 224)) / 255.0\n",
        "#         img = np.expand_dims(img, axis=0)\n",
        "\n",
        "#         # Use the loaded model to make predictions\n",
        "#         predictions = self.model.predict(img)\n",
        "#         species_id = np.argmax(predictions)\n",
        "#         num_ovum = int(np.round(predictions[0][species_id] * 100, 0))\n",
        "#         species = self.species_mapping[species_id]\n",
        "\n",
        "#         return num_ovum, species\n",
        "\n",
        "# # Pass image path as tensor to call method\n",
        "# image_path = tf.constant([r\"C:\\Users\\Mike_Dev\\Desktop\\Schistosoma mansoni.jpg\"])\n",
        "# image_path = tf.squeeze(image_path).numpy()\n",
        "# image_path = tf.strings.unicode_decode(image_path, 'UTF-8')[0]\n",
        "\n",
        "# # Create an instance of the SchistosomaOvaCounter class\n",
        "# counter = SchistosomaOvaCounter()\n",
        "\n",
        "# # Call the `call` method of the `SchistosomaOvaCounter` class on the image tensor\n",
        "# num_ovum, species = counter.call(tf.io.read_file(image_path))\n",
        "\n",
        "# # Print the results\n",
        "# print(f\"Number of Schistosoma ova in the image: {num_ovum}%\")\n",
        "# print(f\"The species of Schistosoma in the image is: {species}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZoXLeOwL1Ok",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "\n",
        "# # Define the SchistosomaOvaCounter class\n",
        "# class SchistosomaOvaCounter(tf.keras.Model):\n",
        "#     def __init__(self):\n",
        "#         super(SchistosomaOvaCounter, self).__init__()\n",
        "#         # Define the layers of the model\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         # Load the image\n",
        "#         image = tf.io.read_file(inputs)\n",
        "#         # Decode the image\n",
        "#         image = tf.io.decode_jpeg(image)\n",
        "#         # Resize the image\n",
        "#         image = tf.image.resize(image, [224, 224])\n",
        "#         # Preprocess the image\n",
        "#         image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
        "#         # Pass the image through the model\n",
        "\n",
        "#         # Return the number of ova and species\n",
        "\n",
        "\n",
        "# # Pass image path as tensor to call method\n",
        "# image_path = tf.constant([r\"C:\\Users\\Mike_Dev\\Desktop\\Schistosoma mansoni.jpg\"])\n",
        "# with tf.compat.v1.Session() as sess:\n",
        "#     image_path = tf.squeeze(image_path).eval(session=sess).decode()\n",
        "# # Create an instance of the SchistosomaOvaCounter class\n",
        "# counter = SchistosomaOvaCounter()\n",
        "# # Call the `call` method of the `SchistosomaOvaCounter` class on the image tensor\n",
        "# num_ovum, species = counter.call(image_path)\n",
        "# # Print the results\n",
        "# print(f\"Number of Schistosoma mansoni ova detected: {num_ovum}\")\n",
        "# print(f\"Schistosoma mansoni species identified: {species}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLuGcd3YL1Ok"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "# from tensorflow.keras.layers import Dense\n",
        "# from tensorflow.keras.models import Model\n",
        "# from tensorflow.keras.preprocessing import image\n",
        "# import numpy as np\n",
        "\n",
        "# class SchistosomaOvaCounter(Model):\n",
        "#     def __init__(self):\n",
        "#         super(SchistosomaOvaCounter, self).__init__()\n",
        "#         self.resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "#         self.pool = tf.keras.layers.GlobalAveragePooling2D()\n",
        "#         self.fc1 = tf.keras.layers.Dense(1024, activation='relu')\n",
        "#         self.fc2 = tf.keras.layers.Dense(1, activation='linear')\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         x = preprocess_input(inputs)\n",
        "#         x = tf.image.resize(x,[200,200])\n",
        "#         x = self.resnet(x)\n",
        "#         x = self.pool(x)\n",
        "#         x = self.fc1(x)\n",
        "#         num_ovum = self.fc2(x)\n",
        "#         return num_ovum\n",
        "\n",
        "\n",
        "# # Load image using tf.io.read_file and decode using tf.image.decode_jpeg\n",
        "# image_path = tf.constant([r\"C:\\Users\\Mike_Dev\\Desktop\\Schistosoma mansoni.jpg\"])\n",
        "# image = tf.io.read_file(tf.squeeze(image_path))\n",
        "# image = tf.image.decode_jpeg(image, channels=3)\n",
        "\n",
        "# # Create an instance of the SchistosomaOvaCounter class\n",
        "# counter = SchistosomaOvaCounter()\n",
        "\n",
        "# # Call the `call` method of the `SchistosomaOvaCounter` class on the image tensor\n",
        "# num_ovum = counter(tf.expand_dims(image, axis=0))\n",
        "\n",
        "# # Print the results\n",
        "# with tf.compat.v1.Session() as sess:\n",
        "#     num_ovum_value = sess.run(num_ovum)\n",
        "\n",
        "# print(f\"Number of Schistosoma mansoni ova detected: {num_ovum_value[0][0]:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hv879LzAL1Om"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "# from tensorflow.keras.layers import Dense, Flatten\n",
        "# from tensorflow.keras.models import Model\n",
        "\n",
        "# # Load the pre-trained ResNet50 model\n",
        "# resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(200, 200, 3))\n",
        "\n",
        "# # Define the new architecture\n",
        "# x = Flatten()(resnet.output)\n",
        "# x = Dense(256, activation='relu')(x)\n",
        "# x = Dense(128, activation='relu')(x)\n",
        "# output = Dense(10, activation='softmax')(x)\n",
        "# model = Model(inputs=resnet.input, outputs=output)\n",
        "\n",
        "# # Compile the new model\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# # Train the\n",
        "# model.fit(\n",
        "#         train_generator,\n",
        "#         steps_per_epoch=train_generator.samples // batch_size,\n",
        "#         epochs=40,\n",
        "#         validation_data=validation_generator,\n",
        "#         validation_steps=validation_generator.samples // batch_size)\n",
        "\n",
        "# # Evaluate the model\n",
        "# loss, accuracy = model.evaluate(test_dir, labels)\n",
        "\n",
        "# # Save the new model\n",
        "# model.save('new_resnet_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aAld88EL1Om"
      },
      "outputs": [],
      "source": [
        "# import cv2\n",
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "\n",
        "# def load_model():\n",
        "#     model_path = \"schisto_ova_classifier.h5\"\n",
        "#     model = tf.keras.models.load_model(model_path)\n",
        "#     return model\n",
        "\n",
        "# def predict_species(image):\n",
        "#     model = load_model()\n",
        "#     image = cv2.resize(image, (128, 128))\n",
        "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "#     image = np.expand_dims(image, axis=0)\n",
        "#     prediction = model.predict(image)\n",
        "#     predicted_class = np.argmax(prediction)\n",
        "#     if predicted_class == 0:\n",
        "#         return \"haematobium\"\n",
        "#     elif predicted_class == 1:\n",
        "#         return \"mansoni\"\n",
        "#     else:\n",
        "#         return None\n",
        "\n",
        "# def predict_haematobium(image):\n",
        "#     # code to predict ovum mask for haematobium species\n",
        "#     pass\n",
        "\n",
        "# def predict_mansoni(image):\n",
        "#     # code to predict ovum mask for mansoni species\n",
        "#     pass\n",
        "\n",
        "# def schistosoma_ova_counter(image_path):\n",
        "#     # Load the image\n",
        "#     image = cv2.imread(image_path)\n",
        "\n",
        "#     # Predict the species of Schistosoma based on the filename\n",
        "#     if \"haematobium\" in image_path.lower():\n",
        "#         species = \"haematobium\"\n",
        "#         ovum_mask = predict_haematobium(image)\n",
        "#     elif \"mansoni\" in image_path.lower():\n",
        "#         species = \"mansoni\"\n",
        "#         ovum_mask = predict_mansoni(image)\n",
        "#     else:\n",
        "#         lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "#         l, a, b = cv2.split(lab_image)\n",
        "#         clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
        "#         l = clahe.apply(l)\n",
        "#         lab_image = cv2.merge((l, a, b))\n",
        "#         image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "#         species = predict_species(image)\n",
        "#         if species == \"haematobium\":\n",
        "#             ovum_mask = predict_haematobium(image)\n",
        "#         elif species == \"mansoni\":\n",
        "#             ovum_mask = predict_mansoni(image)\n",
        "#         else:\n",
        "#             return \"Unable to identify Schistosoma species from image\"\n",
        "\n",
        "#     # Count the number of ovum of the predicted species in the image\n",
        "#     lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "#     ovum_mask = cv2.medianBlur(ovum_mask, 5)\n",
        "#     ovum_mask = cv2.morphologyEx(ovum_mask, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9)))\n",
        "#     contours, hierarchy = cv2.findContours(ovum_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "#     num_ovum = len(contours)\n",
        "\n",
        "#     return f\"{num_ovum} Schistosoma {species} ovum found in the image\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNt9O0LDL1On"
      },
      "source": [
        "This output of the cell below indicates that the CNN model identified Schistosoma mansoni with a probability of 0.997 and Schistosoma japonicum with a probability of 0.0028 in the input image. The probabilities of the other species (Schistosoma haematobium, Schistosoma intercalatum, and Schistosoma mekongi) were 0.0. With 99.7% of S.mansoni and 0.28& of S.japonicum, this could tell of potential HYBRID EGG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-pXC_CSL1On",
        "outputId": "a47ed16f-4b42-49c9-fb2f-75a8d143fcaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Schistosoma haematobium': 0.0, 'Schistosoma intercalatum': 0.0, 'Schistosoma japonicum': 0.0028280779, 'Schistosoma mansoni': 0.99717194, 'Schistosoma mekongi': 0.0}\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Load the pre-trained CNN model\n",
        "model = tf.keras.models.load_model('schistosoma_ova_classifier.h5')\n",
        "\n",
        "# Preprocess the image\n",
        "img = cv2.imread(r\"C:\\Users\\Mike_Dev\\Desktop\\sh and sm.jpg\")\n",
        "img = cv2.resize(img, (200, 200))\n",
        "img = np.expand_dims(img, axis=0)\n",
        "\n",
        "# Pass the image through the CNN model\n",
        "preds = model.predict(img)\n",
        "\n",
        "# Postprocess the output\n",
        "pred_labels = np.argmax(preds, axis=1)\n",
        "counts = np.sum(preds, axis=0)\n",
        "\n",
        "# Return the results\n",
        "species = ['Schistosoma haematobium', 'Schistosoma intercalatum', 'Schistosoma japonicum', 'Schistosoma mansoni', 'Schistosoma mekongi']\n",
        "results = dict(zip(species, counts))\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LH9b-hizL1Oo"
      },
      "source": [
        "Schisto detect and count function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngr3pzDWL1Oo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Define the function\n",
        "def detect_and_count_ova(image_path, model_path):\n",
        "    # Load the pre-trained CNN model\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Preprocess the image\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (200, 200))\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    # Pass the image through the CNN model\n",
        "    preds = model.predict(img)\n",
        "\n",
        "    # Postprocess the output\n",
        "    pred_labels = np.argmax(preds, axis=1)\n",
        "    counts = np.sum(preds, axis=0)\n",
        "\n",
        "    # Define the species labels\n",
        "    species = ['Schistosoma haematobium', 'Schistosoma intercalatum', 'Schistosoma japonicum', 'Schistosoma mansoni', 'Schistosoma mekongi']\n",
        "\n",
        "    # Get the species counts and labels\n",
        "    species_counts = dict(zip(species, counts))\n",
        "    identified_species = [species[i] for i in np.where(pred_labels > 0)[0]]\n",
        "\n",
        "    # Return the results\n",
        "    return identified_species, species_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oIZ9_2zL1Oo"
      },
      "source": [
        "this one identified S. haem and counted S.mansoni :\n",
        "Identified species: ['Schistosoma haematobium']\n",
        "Species counts: {'Schistosoma haematobium': 0.0, 'Schistosoma intercalatum': 0.0, 'Schistosoma japonicum': 0.0, 'Schistosoma mansoni': 1.0, 'Schistosoma mekongi': 0.0}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZSvAc2HL1Oo",
        "outputId": "63b09ea6-c1f0-42e7-80cc-2275956c9e99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Identified species: ['Schistosoma haematobium']\n",
            "Species counts: {'Schistosoma haematobium': 0.0, 'Schistosoma intercalatum': 0.0, 'Schistosoma japonicum': 0.0, 'Schistosoma mansoni': 1.0, 'Schistosoma mekongi': 0.0}\n"
          ]
        }
      ],
      "source": [
        "identified_species, species_counts = detect_and_count_ova(r\"C:\\Users\\Mike_Dev\\Desktop\\multiple sm.jpg\", 'schistosoma_ova_classifier.h5')\n",
        "print('Identified species:', identified_species)\n",
        "print('Species counts:', species_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoANxCU6L1Op"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Define the function\n",
        "def detect_and_count_ovum(image_path, model_path, threshold=0.5):\n",
        "    # Load the pre-trained CNN model\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Preprocess the image\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (200, 200))\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    # Pass the image through the CNN model\n",
        "    preds = model.predict(img)\n",
        "\n",
        "    # Postprocess the output\n",
        "    pred_labels = np.where(preds > threshold)[1]\n",
        "    counts1 = np.sum(preds[:, pred_labels], axis=0)\n",
        "\n",
        "    # Define the species labels\n",
        "    species1 = ['Schistosoma haematobium', 'Schistosoma japonicum', 'Schistosoma mansoni', 'Schistosoma mekongi', 'Schistosoma intercalatum']\n",
        "\n",
        "    # Get the species counts and labels\n",
        "    species_counts1 = dict(zip(species, counts1))\n",
        "    identified_species1 = [species[i] for i in pred_labels]\n",
        "\n",
        "    # Return the results\n",
        "    return identified_species1, species_counts1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mP155796L1Op",
        "outputId": "b32d02c4-eb97-4981-ecc4-9778ce6dc094",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Identified species: ['Schistosoma mansoni']\n",
            "Species counts: {'Schistosoma haematobium': 1.0}\n"
          ]
        }
      ],
      "source": [
        "identified_species, species_counts = detect_and_count_ovum(r\"C:\\Users\\Mike_Dev\\Desktop\\multiple sm.jpg\", 'schistosoma_ova_classifier.h5')\n",
        "print('Identified species:', identified_species)\n",
        "print('Species counts:', species_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46XbD6YSL1Op"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def detect_and_count_ova(image_path, model_path):\n",
        "    # Load the pre-trained CNN model\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Preprocess the image\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (200, 200))\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    # Pass the image through the CNN model\n",
        "    preds = model.predict(img)\n",
        "\n",
        "    # Define the species labels\n",
        "    species = ['Schistosoma haematobium', 'Schistosoma japonicum', 'Schistosoma mansoni', 'Schistosoma mekongi', 'Schistosoma intercalatum']\n",
        "\n",
        "    # Define the morphology of each ovum\n",
        "    morphology = {'Schistosoma haematobium': 'large terminal spine',\n",
        "                  'Schistosoma japonicum': 'small lateral spine',\n",
        "                  'Schistosoma mansoni': 'large lateral spine',\n",
        "                  'Schistosoma mekongi': 'large terminal spine',\n",
        "                  'Schistosoma intercalatum': 'small terminal spine'}\n",
        "\n",
        "    # Count the number of ova detected per species\n",
        "    counts = {}\n",
        "    for i in range(len(preds[0])):\n",
        "        if preds[0][i] > 0.5:\n",
        "            species_name = species[i]\n",
        "            if species_name in counts:\n",
        "                counts[species_name] += 1\n",
        "            else:\n",
        "                counts[species_name] = 1\n",
        "\n",
        "    # Calculate the total number of ova detected\n",
        "    total_count = sum(counts.values())\n",
        "\n",
        "    # Return the results\n",
        "    return counts, morphology, total_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNdm4oE9L1Oq",
        "outputId": "362e092c-9437-47c8-b86b-4ccd14b3af1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counts: {'Schistosoma mekongi': 1}\n",
            "Morphology: {'Schistosoma haematobium': 'large terminal spine', 'Schistosoma japonicum': 'small lateral spine', 'Schistosoma mansoni': 'large lateral spine', 'Schistosoma mekongi': 'large terminal spine', 'Schistosoma intercalatum': 'small terminal spine'}\n",
            "Total count: 1\n"
          ]
        }
      ],
      "source": [
        "counts, morphology, total_count = detect_and_count_ova(r\"C:\\Users\\Mike_Dev\\Desktop\\multiple sm.jpg\", 'schistosoma_ova_classifier.h5')\n",
        "print('Counts:', counts)\n",
        "print('Morphology:', morphology)\n",
        "print('Total count:', total_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP7lgqj_L1Oq"
      },
      "source": [
        "Trying the Masked R-CNN in place of CNN that i've been using all the while without satisfactory results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0RnyWBAL1Oq"
      },
      "outputs": [],
      "source": [
        "conda install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KI9JwV3AL1Oq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6bfW0R4L1Or",
        "scrolled": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}